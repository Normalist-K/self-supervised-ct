{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "# distributed training\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from model import load_optimizer, save_model\n",
    "from modules import SimCLR, NT_Xent, get_resnet, EarlyStopping\n",
    "from modules.transformations import TransformsSimCLR\n",
    "from modules.sync_batchnorm import convert_model\n",
    "from utils import yaml_config_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "args_str = '' \n",
    "args, _ = parser.parse_known_args(args=args_str)\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(args.device)\n",
    "args.num_gpus = torch.cuda.device_count()\n",
    "args.world_size = args.gpus * args.nodes\n",
    "gpu = 0\n",
    "rank = args.nr * args.gpus + gpu\n",
    "\n",
    "if args.nodes > 1:\n",
    "        dist.init_process_group(\"nccl\", rank=rank, world_size=args.world_size)\n",
    "        torch.cuda.set_device(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "#------- added by young ---------\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "if args.gpus > 1:\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    '/home/opticho/source/SimCLR/datasets/dataset2(3)/train/train', \n",
    "    transform=TransformsSimCLR(size=(args.image_size, args.image_size)).test_transform)\n",
    "valid_dataset = torchvision.datasets.ImageFolder(\n",
    "    '/home/opticho/source/SimCLR/datasets/dataset2(3)/train/valid', \n",
    "    transform=TransformsSimCLR(size=(args.image_size, args.image_size)).test_transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    '/home/opticho/source/SimCLR/datasets/dataset2(3)/test', \n",
    "    transform=TransformsSimCLR(size=(args.image_size, args.image_size)).test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-247e983d6e45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_loader = torch.utils.data.DataLoader(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=args.workers,\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=args.workers,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=args.workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv2d = torch.nn.Conv2d(3, 3, 3, padding=1)\n",
    "        self.net = EfficientNet.from_pretrained('efficientnet-b0', num_classes=3, include_top = False)\n",
    "        self.seq = torch.nn.Sequential(\n",
    "            nn.BatchNorm1d(1280),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d(x)\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, 1280)\n",
    "        x = self.seq(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([32, 3, 244, 244])\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "torch.Size([32, 1280, 1, 1])\n",
      "torch.Size([32, 1280])\n",
      "torch.Size([32, 1280])\n",
      "torch.Size([32, 512])\n",
      "torch.Size([32, 512])\n",
      "torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.Tensor(32, 3, 244, 244)\n",
    "\n",
    "out = nn.Conv2d(3, 3, 3, padding=1)(inp)\n",
    "print(out.shape)\n",
    "out = EfficientNet.from_pretrained('efficientnet-b0', num_classes=3, include_top = False)(out)\n",
    "print(out.shape)\n",
    "out = out.view(-1, 1280)\n",
    "out = nn.BatchNorm1d(1280)(out)\n",
    "print(out.shape)\n",
    "out = nn.Dropout(0.5)(out)\n",
    "print(out.shape)\n",
    "out = nn.Linear(1280, 512)(out)\n",
    "out = nn.ReLU()(out)\n",
    "print(out.shape)\n",
    "out = nn.BatchNorm1d(512)(out)\n",
    "print(out.shape)\n",
    "out = nn.Dropout(0.5)(out)\n",
    "print(out.shape)\n",
    "out = nn.Linear(512, 3)(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "# initialize ResNet\n",
    "# model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# ct = 0 \n",
    "# for child in model.children(): \n",
    "#     ct += 1 \n",
    "#     if ct < 6:\n",
    "#         for param in child.parameters():\n",
    "#             param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "model = Model()\n",
    "model.to(args.device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "device = args.device\n",
    "valid_loss_min = np.Inf\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "avg_train_losses = []\n",
    "avg_valid_losses = []\n",
    "train_acc, valid_acc = [], []\n",
    "best_acc = 0.0\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10000.. \n",
      "Training Loss: 0.933960 \tValidation Loss: 1.078514 \tTrraining Accuracy: 56.875000 \tValidation Accuracy: 48.592593\n",
      "Epoch 2/10000.. \n",
      "Training Loss: 0.563557 \tValidation Loss: 1.221853 \tTrraining Accuracy: 77.867647 \tValidation Accuracy: 36.148148\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 3/10000.. \n",
      "Training Loss: 0.328918 \tValidation Loss: 1.333228 \tTrraining Accuracy: 88.051471 \tValidation Accuracy: 39.703704\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 4/10000.. \n",
      "Training Loss: 0.218179 \tValidation Loss: 1.486598 \tTrraining Accuracy: 92.058824 \tValidation Accuracy: 45.037037\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 5/10000.. \n",
      "Training Loss: 0.139501 \tValidation Loss: 1.063093 \tTrraining Accuracy: 95.330882 \tValidation Accuracy: 59.703704\n",
      "Epoch 6/10000.. \n",
      "Training Loss: 0.097880 \tValidation Loss: 0.775117 \tTrraining Accuracy: 96.838235 \tValidation Accuracy: 72.888889\n",
      "Epoch 7/10000.. \n",
      "Training Loss: 0.080967 \tValidation Loss: 0.799303 \tTrraining Accuracy: 97.316176 \tValidation Accuracy: 78.370370\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 8/10000.. \n",
      "Training Loss: 0.058336 \tValidation Loss: 0.761352 \tTrraining Accuracy: 98.198529 \tValidation Accuracy: 76.740741\n",
      "Epoch 9/10000.. \n",
      "Training Loss: 0.044131 \tValidation Loss: 0.735435 \tTrraining Accuracy: 98.639706 \tValidation Accuracy: 75.851852\n",
      "Epoch 10/10000.. \n",
      "Training Loss: 0.048205 \tValidation Loss: 0.790316 \tTrraining Accuracy: 98.566176 \tValidation Accuracy: 77.925926\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 11/10000.. \n",
      "Training Loss: 0.038590 \tValidation Loss: 0.880508 \tTrraining Accuracy: 98.860294 \tValidation Accuracy: 76.592593\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 12/10000.. \n",
      "Training Loss: 0.044959 \tValidation Loss: 0.921063 \tTrraining Accuracy: 98.676471 \tValidation Accuracy: 75.555556\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 13/10000.. \n",
      "Training Loss: 0.030095 \tValidation Loss: 0.806849 \tTrraining Accuracy: 98.970588 \tValidation Accuracy: 77.777778\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 14/10000.. \n",
      "Training Loss: 0.030168 \tValidation Loss: 0.904873 \tTrraining Accuracy: 98.823529 \tValidation Accuracy: 76.888889\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Best val Acc: 78.370370\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "    total_valid = 0\n",
    "    correct_valid = 0\n",
    "\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        predicted = outputs.argmax(1)\n",
    "        total_train += labels.nelement()\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        train_accuracy = correct_train / total_train\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        accuracy = 0\n",
    "        for inputs, labels in valid_loader:\n",
    "            \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_losses.append(loss.item())\n",
    "            # Calculate accuracy\n",
    "            predicted = outputs.argmax(1)\n",
    "            total_valid += labels.nelement()\n",
    "            correct_valid += (predicted == labels).sum().item()\n",
    "            valid_accuracy = correct_valid / total_valid\n",
    "        \n",
    "    train_loss = np.average(train_losses)\n",
    "    valid_loss = np.average(valid_losses)\n",
    "    avg_train_losses.append(train_loss)\n",
    "    avg_valid_losses.append(valid_loss)\n",
    "    valid_acc.append(valid_accuracy) \n",
    "    train_acc.append(train_accuracy)\n",
    "\n",
    "    # calculate average losses\n",
    "    \n",
    "    # print training/validation statistics \n",
    "    print(f\"Epoch {epoch+1}/{epochs}.. \")\n",
    "    print('Training Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTrraining Accuracy: {:.6f} \\tValidation Accuracy: {:.6f}'.format(\n",
    "        train_loss, valid_loss, train_accuracy*100, valid_accuracy*100))\n",
    "    train_losses = []\n",
    "    valid_losses = []        \n",
    "    if valid_accuracy > best_acc:\n",
    "        best_acc = valid_accuracy\n",
    "    early_stopping(valid_loss, args, model, optimizer, save=False)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    \n",
    "print('Best val Acc: {:4f}'.format(best_acc*100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_specificity(specificity):\n",
    "    print('\\t\\tspecificity')\n",
    "    print('')\n",
    "\n",
    "    print(f'       covid\\t{specificity[0]:.2f}')\n",
    "    print(f'     healthy\\t{specificity[1]:.2f}')\n",
    "    print(f'      others\\t{specificity[2]:.2f}')\n",
    "    print('')\n",
    "\n",
    "    macro_specificity = sum(specificity) / 3.0\n",
    "    print(f'   macro avg\\t{macro_specificity:.2f}')\n",
    "\n",
    "    weighted = [434/835, 152/835, 249/835] \n",
    "    weighted_specificity = weighted @ specificity\n",
    "    print(f'weighted avg\\t{weighted_specificity:.2f}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confusion Matrix:\n [[324  22  56]\n [  2 118  13]\n [ 43  35 163]]\n\t\tspecificity\n\n       covid\t0.88\n     healthy\t0.91\n      others\t0.87\n\n   macro avg\t0.89\nweighted avg\t0.88\n\n              precision    recall  f1-score   support\n\n       covid       0.88      0.81      0.84       402\n     healthy       0.67      0.89      0.77       133\n      others       0.70      0.68      0.69       241\n\n    accuracy                           0.78       776\n   macro avg       0.75      0.79      0.77       776\nweighted avg       0.79      0.78      0.78       776\n\n"
     ]
    }
   ],
   "source": [
    "loss_epoch = 0\n",
    "accuracy_epoch = 0\n",
    "model.eval()\n",
    "pred = []\n",
    "true = []\n",
    "soft = []\n",
    "for step, (x, y) in enumerate(test_loader):\n",
    "    model.zero_grad()\n",
    "\n",
    "    x = x.to(args.device)\n",
    "    y = y.to(args.device)\n",
    "\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    # for majority voting\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    s = softmax(outputs).cpu().detach().tolist()\n",
    "    for i in range(len(s)):\n",
    "        soft.append(s[i])\n",
    "\n",
    "    predicted = outputs.argmax(1)\n",
    "    preds = predicted.cpu().numpy()\n",
    "    labels = y.cpu().numpy()\n",
    "    preds = np.reshape(preds, (len(preds), 1))\n",
    "    labels = np.reshape(labels, (len(preds), 1))\n",
    "\n",
    "    for i in range(len(preds)):\n",
    "        pred.append(preds[i][0].item())\n",
    "        true.append(labels[i][0].item())\n",
    "    \n",
    "    acc = (predicted == y).sum().item() / y.size(0)\n",
    "    accuracy_epoch += acc\n",
    "\n",
    "    loss_epoch += loss.item()\n",
    "\n",
    "cnf_matrix = confusion_matrix(true, pred)\n",
    "print('Confusion Matrix:\\n', cnf_matrix)\n",
    "\n",
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "accuracy_epoch = np.diag(cnf_matrix).sum().item() / len(true)\n",
    "\n",
    "# Specificity or true negative rate\n",
    "specificity = TN/(TN+FP) \n",
    "\n",
    "print_specificity(specificity)\n",
    "\n",
    "report = classification_report(true, pred, target_names=['covid', 'healthy', 'others'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}